# DataStream: MySQL & ClickHouse

Приложение для передачи данных из MySQL в ClickHouse.

## Особенности

- Данные о подключениях к MySQL берутся из специальной сервисной таблицы
- Универсальная обработка таблиц для всех подключаемых БД
- Сбор всех данных в одну таблицу с префиксом базы данных
- Автоматическое обновление данных в ClickHouse
- Интеграция с Apache Airflow для мониторинга процессов

## Требования

- Python 3.7+
- MySQL 5.7+
- ClickHouse 21.8+
- Apache Airflow 2.0+ (для мониторинга)

## Установка

1. Клонируйте репозиторий:
```
git clone <репозиторий>
cd DataStream-MySQL-\&-Clickhouse
```

2. Установите зависимости:
```
uv sync 
```

3. Создайте файл .env на основе env.example:
```
cp env.example app/.env
```

4. Отредактируйте .env файл, указав настройки подключения к вашим базам данных.

5. Создайте сервисную базу данных и таблицу для настроек подключений: mysql_connections через phpMyAdmin
```
mysql -u root -p < service_db_setup.sql
```

## Настройка подключений

После создания сервисной таблицы, добавьте в нее информацию о подключениях к базам данных MySQL, которые вы хотите синхронизировать с ClickHouse:

```sql
INSERT INTO mysql_connections 
    (name, host, port, user, password, `database`, enabled, tables, description)
VALUES
    ('my_database', 'mysql-server', 3306, 'user', 'password', 'db_name', 1, 'table1,table2', 'Описание подключения');
```

Параметры:
- `name` - уникальное имя подключения
- `host` - хост сервера MySQL
- `port` - порт MySQL (по умолчанию 3306)
- `user` - пользователь MySQL
- `password` - пароль пользователя
- `database` - имя базы данных для синхронизации
- `enabled` - активно ли подключение (1 - да, 0 - нет)
- `tables` - список таблиц для синхронизации через запятую (если пусто - все таблицы)
- `description` - описание подключения

## Использование

### Запуск синхронизации вручную

Для запуска синхронизации выполните:

```
uv run -m app.main
```

Дополнительные параметры:
- `--json` - вывод результатов в формате JSON
- `--output <файл>` - сохранение результатов в указанный файл

### Использование Airflow

1. Скопируйте DAG в директорию dags вашего Airflow:
```
cp dags/data_sync_dag.py <путь_к_airflow>/dags/
```

2. Убедитесь, что путь к приложению указан верно в файле DAG.

3. Перезапустите Airflow scheduler или дождитесь автоматического обнаружения нового DAG.

4. DAG будет запускаться по расписанию (по умолчанию - раз в день), или вы можете запустить его вручную через веб-интерфейс Airflow.

## Структура проекта

Приложение имеет следующую структуру:

```
DataStream-MySQL-&-Clickhouse/
├── app/                      # Основной код приложения
│   ├── db/                   # Модули для работы с БД
│   │   ├── clickhouse.py     # Работа с ClickHouse
│   │   └── mysql.py          # Работа с MySQL
│   ├── models/               # Модели данных
│   │   └── service_db.py     # Модели сервисных таблиц
│   ├── services/             # Бизнес-логика 
│   │   ├── data_service.py   # Сервис для обработки данных
│   │   └── sync_service.py   # Сервис для синхронизации данных
│   ├── config.py             # Конфигурация приложения
│   └── main.py               # Точка входа приложения
├── dags/                     # DAG-и для Airflow
│   └── data_sync_dag.py      # DAG для синхронизации данных
├── env.example               # Пример файла с переменными окружения
├── service_db_setup.sql      # SQL скрипт для создания сервисной таблицы
└── requirements.txt          # Зависимости проекта
``` 